{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40vPF6mA81Vr",
        "outputId": "a319341f-0ebf-4047-9546-03922a4ec472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. \ub2e4\uc74c \ubb38\uc7a5 \uc608\uce21 \ubaa8\ub378\uacfc \ud1a0\ud06c\ub098\uc774\uc800"
      ],
      "metadata": {
        "id": "2bNDwqgZ9H7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForNextSentencePrediction\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "4TeJ_mjB84RT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "99be849652634a769be1d37ff7979ae9",
            "992835d1a2ec49e2bb555b3476444402",
            "e3f1f97f82c54d949165958499b022cb",
            "698e6f227d014d9087ac77ff89a43b59",
            "9c263e2129424988981aebcba113f198",
            "8dfd8b53274349a3a6bec4805d6c68e5",
            "02275854537d4fc9878caa37951da5cc",
            "d413b26c891a49aeadc35316a1abc73e",
            "3f6d94027d4b4b11a17602c6e0539057",
            "6d461b11cae74279ac121eadffbccb7b",
            "2792de5ca4dd4088a95e164293b18dfd",
            "1350ed81a7cb4a0a9e48906415b31a83",
            "d765c3a5a4ee4766ad2835c8da308b58",
            "729bcdf12ef647a2a1bbd2eb0cac640b",
            "75e7a0014d30498aadc42d21b5f085b4",
            "e4660adee7d24a92a72fed0f1b8bdbc5",
            "35d180622e5c4bba9fde8eb4b83b928d",
            "695bc882036f4f39826b3d20523ce3fe",
            "8a80d2ff37bf46528ec588982608d45f",
            "22b163a574a54b1aaddc26844dce6864",
            "062a65d79eb2492aaa8affb5850c9e5d",
            "e299f963dd5b4fbbb1480e52b021a52e",
            "7ffc7ded579b420c867c2cb0207f14fb",
            "6ceefc9bcfc941aa86ac47b53a1b870f",
            "f276e2bfc5ad4b619f5388ed6cfdbba1",
            "27b21a16ca8048b1beb605e2784a4b16",
            "748154b0aa0f485fb05acd3b864075da",
            "a69bd52e882a4a84a7679ff9d623b2eb",
            "2eb508fbcb574c6cac387ec8ee3ec1dc",
            "3f7032aa40b14cb68f6c387324aaa03e",
            "5fa443d048ec43b392b1d290ff311b49",
            "d1350e81c3a14c12b573cfef6c4599fd",
            "418ca86a50b246fdb588915e7a4ad57b",
            "b3f44d7adbf8418d86903258f69519e5",
            "c0f4c97613d64b74ae7a2162e5962c46",
            "a295296a5a714e3c8b502c5a685a0659",
            "bd4b72dbad4d4799be1d90298ac6837c",
            "2ae56b4da0bc4f09bc683dd1d6319627",
            "f852eb600a3f4a68bbfe1257b8a3303e",
            "74a6e856016d40b5b10e3b9eba3ff429",
            "832fba6cf4e84bdbb1e60dfdedb79c10",
            "9da7c178045b45b2a1863dde264ee43b",
            "fed5b54e5e6b43b2830d9b06340c3c8c",
            "879cce916175459fa1b0fa46c8c3af19",
            "19630b7e0e464f1d85bcf9167aa6b21b",
            "0eb6534b7f17403989a0aae12bb7a28b",
            "938a4da9fa044beb9fef0a89cac773af",
            "c2c71711b0e14d6c83c80294544796b5",
            "6deebaeca62d49f4bca311f702002799",
            "2b474f396fc5439e805ef0cd3f0e7220",
            "8d0961f2869841fc860747984ad84d62",
            "08d948abf4f149a2b67fa7812b829ec5",
            "6c4dd2e094d34906af00957d26d34a0b",
            "ea796afadf3a4e18abdc82d49c1c916f",
            "7f25ae91cc474ad0a7be929214f50a14"
          ]
        },
        "id": "ZOsSIUOa86B4",
        "outputId": "e801b6e7-71d8-4b3f-cac9-8ee3bdee2b17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99be849652634a769be1d37ff7979ae9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1350ed81a7cb4a0a9e48906415b31a83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ffc7ded579b420c867c2cb0207f14fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3f44d7adbf8418d86903258f69519e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19630b7e0e464f1d85bcf9167aa6b21b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. BERT\uc758 \uc785\ub825"
      ],
      "metadata": {
        "id": "O4iCwBLF9Jbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
        "next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\""
      ],
      "metadata": {
        "id": "hRkeKM9p860Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')"
      ],
      "metadata": {
        "id": "Q3ENYwJy870A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoding['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAlRFrE_88y4",
        "outputId": "8cd14ddb-4628-4bae-bbf0-f1be1b0a1583"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1999,  3304,  1010, 10733,  2366,  1999,  5337, 10906,  1010,\n",
            "          2107,  2004,  2012,  1037,  4825,  1010,  2003,  3591,  4895, 14540,\n",
            "          6610,  2094,  1012,   102, 10733,  2003,  8828,  2007,  1996,  2224,\n",
            "          1997,  1037,  5442,  1998,  9292,  1012,  1999, 10017, 10906,  1010,\n",
            "          2174,  1010,  2009,  2003,  3013,  2046, 17632,  2015,  2000,  2022,\n",
            "          8828,  2096,  2218,  1999,  1996,  2192,  1012,   102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
        "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ6h1g2X9BDg",
        "outputId": "44b58e17-101e-4882-bbfd-2eca6d8574af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] : 101\n",
            "[SEP] : 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(encoding['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOm_aiJW9CSx",
        "outputId": "46524721-759a-4dd2-f769-04630aceeda5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoding['token_type_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7gbLJUF9DoR",
        "outputId": "b5e05b88-ed10-4902-b022-abc6226881bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. \ub2e4\uc74c \ubb38\uc7a5 \uc608\uce21\ud558\uae30"
      ],
      "metadata": {
        "id": "Ij8xVPdW9LR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])\n",
        "probs = torch.nn.functional.softmax(pred.logits, dim=1)  # Softmax \uc801\uc6a9\ud558\uc5ec \ud655\ub960 \uc5bb\uae30\n",
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RVv92gT9EjB",
        "outputId": "9cc2bfef-7358-4e64-d873-ebf26d4795d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 2.8382e-06]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_sentence_label = torch.argmax(probs, dim=1).item()  # \uc608\uce21\ub41c \ub77c\ubca8 \uc5bb\uae30\n",
        "print('\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 :', next_sentence_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m7rmil79FgB",
        "outputId": "b31221e6-eeeb-4fd7-9b5d-5cbaee7586ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \uc0c1\uad00\uc5c6\ub294 \ub450 \uac1c\uc758 \ubb38\uc7a5\n",
        "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
        "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
        "\n",
        "pred = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])\n",
        "probs = torch.nn.functional.softmax(pred.logits, dim=1)  # Softmax \uc801\uc6a9\ud558\uc5ec \ud655\ub960 \uc5bb\uae30\n",
        "next_sentence_label = torch.argmax(probs, dim=1).item()  # \uc608\uce21\ub41c \ub77c\ubca8 \uc5bb\uae30\n",
        "print('\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 :', next_sentence_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0gbic7y9MzR",
        "outputId": "0fd33dee-d324-4350-b433-72fdd880098c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. \ud55c\uad6d\uc5b4 \ubaa8\ub378\uc758 \ub2e4\uc74c \ubb38\uc7a5 \uc608\uce21 \ubaa8\ub378\uacfc \ud1a0\ud06c\ub098\uc774\uc800"
      ],
      "metadata": {
        "id": "vqS6O7NO9QY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForNextSentencePrediction\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "YQ4dUda89RDj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForNextSentencePrediction.from_pretrained('klue/bert-base')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "7a4b30bd152f4c999df6ff73f484b8fe",
            "5c2365385bfc479eb04b02f86901b303",
            "e1476af16c5a4b4d82b707e3a6290d28",
            "d57b74237ddb4f448bfb5e09cc8060e9",
            "c1a474bc5b944ab19fdf7c600f9361e6",
            "74fff7a691b6452e913a736b102b7752",
            "81c3ed26743345e7aa7f5452f8a43c68",
            "bfb08cfa8ffa43f699b2cfb5c33a0ab3",
            "d9a15571844e460580084ad13c70eebd",
            "955d3a991c424b3faf276712931bc588",
            "94e23fb85a4f4154a3e418f0266b3e71",
            "a6d156cfe04541eab27def2b72deb981",
            "301b624abaa24bc2bc525b34bfda94f6",
            "3ddf4e307cd84409bb925238522f036f",
            "aac4d34cbaf247a7924c16d6427fdd19",
            "c5367d6f851540b9b5eb7c55ee53bc13",
            "6157e0b249ae4e27af89eb17df14045b",
            "1eca1a19f3a74bb19d2aed3f7f6a583c",
            "b9c587a627bd450fa61f2fb986fb45d3",
            "fc30bd1984aa4dcc9daea6999485fb6c",
            "853f44ccff0f43aba1b09c570ec707ec",
            "d4bf55189e1a4b8c8d573eeb5aec0ef9",
            "a19ca2b460464209936f856b8216e26d",
            "604ecf81002242e1b1a608ce3214180f",
            "25e8ea9ceb2144419cc4323d1b182ab5",
            "403b23b7b9cf48759074098655e22aa7",
            "1b64d3d49a60461cb9c1850545e0184e",
            "b23a5583d7774fcdb1c895f8d1066677",
            "489c03a906874d33b91a6a3514a76d7f",
            "2303bd7f90844428bf6df8eb90898bdf",
            "96365b8897134b2c810372ab4f254412",
            "576a1f26b5a24a5b87df3a8abd66be60",
            "524458e0202d47f8ade601cbd786d647",
            "4314d03e9efa4dd0a21ca863ad38fecb",
            "43d9176cf13942f2b716731a04d56b7a",
            "f2bef474e20946b2a2b95065c1a22842",
            "6deb0810a1414190bfe89780e9721fd9",
            "c0f68380911e409c8a285fa503da91ee",
            "97050fa919394e6fbc919a2b84fb7e9a",
            "c9d9795033c2433b929e1f8ed6f33d28",
            "7f47ad4061784b6f99e0f5f18b86e4d4",
            "e71c2f27ed8b4c90be6bcc7d43ea15e1",
            "902f69516e3b48eca310e2fa320d1782",
            "f7757f55374d4e41a259b1cd3a5e1d10",
            "776b0ad3bc0f45f897176e96c8fe5465",
            "0eec8f054de945979be04e0056e31f83",
            "64151b9dfd3c4115b425cbd80e26daf6",
            "f8409dff6b5b4ed9bcb75d65b7d3f7cf",
            "be83dc98e6ae448393e8adce16b72d55",
            "b90a248193e243208a260c920fe64058",
            "980ef9280ad14d2fb92567858936f6f4",
            "8ca271c74d564d4cafddb9f13797d08f",
            "9ac4a3952f624ae5adedfef600793741",
            "69c8cd8a91fc473bae8c3e24503ba154",
            "6d2f4993c3ce40ea9ce5ea69f6715b0a",
            "f922ae4ca6e145c7a771afeb9a3d78f1",
            "861c1818a1064ababa6fb56552c46fb3",
            "6290eb3135fd44cc8303804bcbb7571b",
            "6a190dc0d2d949faa65739615fafbd19",
            "da10d18c127f47dc8a0762d185426b46",
            "6a9123f5c43548d48932361d490051e9",
            "ae522ef5818a4fec8c4604e8b76d9aa6",
            "39cc6d82db1a486db90e36394eb2fe2d",
            "78a808b01a3d422a9019ba1ef8adbc85",
            "e1a18461cc9a4d27afd14e1213288621",
            "36c24f2f47b64fb385f7558804416600"
          ]
        },
        "id": "lCt2id7w9R2I",
        "outputId": "84e8dca4-3cc7-430d-d587-5cc0823e16c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a4b30bd152f4c999df6ff73f484b8fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6d156cfe04541eab27def2b72deb981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a19ca2b460464209936f856b8216e26d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4314d03e9efa4dd0a21ca863ad38fecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "776b0ad3bc0f45f897176e96c8fe5465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f922ae4ca6e145c7a771afeb9a3d78f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. \ub2e4\uc74c \ubb38\uc7a5 \uc608\uce21\ud558\uae30"
      ],
      "metadata": {
        "id": "YmoFXLZX9Tpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \uc774\uc5b4\uc9c0\ub294 \ub450 \uac1c\uc758 \ubb38\uc7a5\n",
        "prompt = \"2002\ub144 \uc6d4\ub4dc\ucef5 \ucd95\uad6c\ub300\ud68c\ub294 \uc77c\ubcf8\uacfc \uacf5\ub3d9\uc73c\ub85c \uac1c\ucd5c\ub418\uc5c8\ub358 \uc138\uacc4\uc801\uc778 \ud070 \uc794\uce58\uc785\ub2c8\ub2e4.\"\n",
        "next_sentence = \"\uc5ec\ud589\uc744 \uac00\ubcf4\ub2c8 \ud55c\uad6d\uc758 2002\ub144 \uc6d4\ub4dc\ucef5 \ucd95\uad6c\ub300\ud68c\uc758 \uc900\ube44\ub294 \uc644\ubcbd\ud588\uc2b5\ub2c8\ub2e4.\"\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
        "\n",
        "pred = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])\n",
        "probs = torch.nn.functional.softmax(pred.logits, dim=1)  # Softmax \uc801\uc6a9\ud558\uc5ec \ud655\ub960 \uc5bb\uae30\n",
        "next_sentence_label = torch.argmax(probs, dim=1).item()  # \uc608\uce21\ub41c \ub77c\ubca8 \uc5bb\uae30\n",
        "print('\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 :', next_sentence_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoayTmcv9SrY",
        "outputId": "4d509c6b-086b-49e6-c695-bad5648bd695"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \uc0c1\uad00\uc5c6\ub294 \ub450 \uac1c\uc758 \ubb38\uc7a5\n",
        "prompt = \"2002\ub144 \uc6d4\ub4dc\ucef5 \ucd95\uad6c\ub300\ud68c\ub294 \uc77c\ubcf8\uacfc \uacf5\ub3d9\uc73c\ub85c \uac1c\ucd5c\ub418\uc5c8\ub358 \uc138\uacc4\uc801\uc778 \ud070 \uc794\uce58\uc785\ub2c8\ub2e4.\"\n",
        "next_sentence = \"\uadf9\uc7a5\uac00\uc11c \ub85c\ub9e8\uc2a4 \uc601\ud654\ub97c \ubcf4\uace0\uc2f6\uc5b4\uc694\"\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
        "\n",
        "pred = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])\n",
        "probs = torch.nn.functional.softmax(pred.logits, dim=1)  # Softmax \uc801\uc6a9\ud558\uc5ec \ud655\ub960 \uc5bb\uae30\n",
        "next_sentence_label = torch.argmax(probs, dim=1).item()  # \uc608\uce21\ub41c \ub77c\ubca8 \uc5bb\uae30\n",
        "print('\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 :', next_sentence_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skYItp399XqQ",
        "outputId": "80417890-5af7-4c99-ab68-ae96d4ba9444"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ucd5c\uc885 \uc608\uce21 \ub808\uc774\ube14 : 1\n"
          ]
        }
      ]
    }
  ]
}