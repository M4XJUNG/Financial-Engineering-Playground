{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2rd2GYlnYGX"
      },
      "source": [
        "# KorNLI \ubd84\ub958"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7_xRg2EJ6RM",
        "outputId": "24cd0fec-0901-40d1-9782-6c407bc25f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewJFnCDHriqX"
      },
      "source": [
        "## \ub370\uc774\ud130\uc14b \ub85c\ub4dc \ubc0f \uad6c\uc870 \ud655\uc778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpdkpZkTUYHy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308,
          "referenced_widgets": [
            "30cc7cdc8ea748ecb2d25c7e8066a321",
            "6c88fe538c0b43db870a540ff1dfc683",
            "1e44957fc6654c32969ea0985158b78b",
            "d545ad7a57d74dfc8df13fdc238ed4ba",
            "cb2e71f78fd3405799a2eb3ae3d2b1b6",
            "d03fd7450b5648b29c3c575d0aabe09c",
            "b267c657b8eb4201845d99dd5baccb36",
            "ba18a0919b55429a84956ff3ee464ba3",
            "918fbe06c26c43169b221014de4e6f72",
            "d61fcba0e29e4ea7b23dd251e2a9c65b",
            "921bc5f1ce3d4564bcae0913427c6e0f",
            "c102160b11304779bf4bec35545fca1f",
            "774adbf152f6424792f3cec45ad46e4f",
            "3153f6c888184b88b79ceb42370dc08e",
            "c133a6fd9607403d913262a79245761b",
            "81ca4ca886e24504a73d7e57c5079906",
            "31e1f4f6ac514d92a2a0844f4caa7457",
            "d1b2f325f82b4068bcf071081c4841ba",
            "9be46e6ad6274f2e9f9e1ab9abb94e1e",
            "3ff5302296e2450188f0263506aa6606",
            "2e70cf6e92b14aef9f2c64b90ae7afe7",
            "332b22ffa86244d2b99c7946dda7dc8d",
            "a4c8416d49844bdc8b0d0cf9c0861fa6",
            "0ed3fae7380e47a891c53acab4eee47d",
            "eeaf431bbbf441cdb5dc748e55a0e0e1",
            "1a496573121f46b685026fb3807a84e0",
            "93c1237e570d4d28bc951ac4b5d51d2a",
            "ddeff98a4784484ebcdb8181d04c52e5",
            "ab859701df244655a30dba715fc5526d",
            "ecab7dad8fff4bfcb9f5474de7f0b916",
            "77eb2af0fc4d436baeff41e56efe1f4d",
            "d0aa4cbb699646f28b79f2825a90bbd4",
            "a2b24730ea6c4296a059b286112e97c4",
            "6f6b98cdd41c4504875f11e78bc82bf8",
            "f69a75bfb9de441b8804b0b23125df94",
            "2094c36547704c888fdc9517c36a5343",
            "0f86657f282e4a46b79e4d2a90d8c402",
            "acc3aa64908e486e89faafa8c9e233d7",
            "fe4fe0780b27464ba10e7c1a2c5d0c15",
            "26482f41aafe4079bcc6530015ee5ce1",
            "c4381477fce14063a0365bee35658d47",
            "d76529d442c842729f8343a8bd706b57",
            "59b6a403cc0b4863afdb1d229e2c7fbd",
            "17cdf561a85d45f7953a166af091afe4",
            "d7bd15f60b404c7f9a432c82840ff1e3",
            "eb38c9e91f9f4349a8be4b793037b383",
            "765c50ea67dd4ec6adff4178f4459729",
            "97586480ef7a4400a0e0cf1dec98c464",
            "ab3984c42f014e949751e46ef22ad994",
            "e1fa2b940774404abef1b33bc140140c",
            "d79feb43163e4b449ad461b61e52681a",
            "a5d3762dbc454e5280d2cf8ea4592256",
            "5a1e8c0376d24796b20370a3b6db1a74",
            "246a94fa7ee34abfbc18e32eececa59c",
            "fb6c569f0f9e4f08b10bbd4bbcdd0ae4"
          ]
        },
        "outputId": "6b814bcf-c6c8-4aca-88f4-88780181571d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30cc7cdc8ea748ecb2d25c7e8066a321"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c102160b11304779bf4bec35545fca1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/224k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4c8416d49844bdc8b0d0cf9c0861fa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/24998 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f6b98cdd41c4504875f11e78bc82bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7bd15f60b404c7f9a432c82840ff1e3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# NLI \ub370\uc774\ud130 \uc911 \ud559\uc2b5 \ub370\uc774\ud130(split=\"train\")\ub97c \ub85c\ub4dc.\n",
        "cs = load_dataset(\"klue\", \"nli\", split=\"train\")\n",
        "\n",
        "# NLI \ub370\uc774\ud130 \uc911 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130(split=\"validation\")\uc744 \ub85c\ub4dc.\n",
        "test_cs = load_dataset(\"klue\", \"nli\", split=\"validation\")\n",
        "\n",
        "# \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud558\uc5ec 9:1 \ube44\uc728\ub85c \ubd84\ud560\ud558\uace0 \uac01\uac01 train_cs\uc640 valid_cs\uc5d0 \uc800\uc7a5\n",
        "cs = cs.train_test_split(0.1, seed=777)\n",
        "train_cs = cs[\"train\"]\n",
        "valid_cs = cs[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-GDhPWVowZp",
        "outputId": "79a43685-322b-4867-b49a-263002674dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['guid', 'source', 'premise', 'hypothesis', 'label'],\n",
              "    num_rows: 22498\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYT1wh7_o00q",
        "outputId": "0bee33ed-610a-43f9-84ce-6f57b728df9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['guid', 'source', 'premise', 'hypothesis', 'label'],\n",
              "    num_rows: 2500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "valid_cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn9UKWTko2Pn",
        "outputId": "67adf12a-ccd6-48f4-a9ad-d355a8f9ad40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['guid', 'source', 'premise', 'hypothesis', 'label'],\n",
              "    num_rows: 3000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "test_cs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz98cJCasPgI"
      },
      "source": [
        "## \ub370\uc774\ud130\uc14b \uc804\ucc98\ub9ac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocBb-25SR-a0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# BERT \uc0ac\uc6a9\uc744 \uc704\ud568\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# for padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# \uc804\ucc98\ub9ac \ubc0f \ud3c9\uac00 \uc9c0\ud45c\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVPmUqsMqpFJ"
      },
      "outputs": [],
      "source": [
        "# \ud6c8\ub828 \ub370\uc774\ud130, \uac80\uc99d \ub370\uc774\ud130, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c `[CLS] \ubb38\uc7a5 [SEP]` \uad6c\uc870\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
        "\n",
        "train_sentences = list(map(lambda train_cs: '[CLS] ' + str(train_cs['premise']) + ' [SEP] ' + str(train_cs['hypothesis']) + ' [SEP]', train_cs))\n",
        "validation_sentences = list(map(lambda valid_cs: '[CLS] ' + str(valid_cs['premise']) + ' [SEP] ' + str(valid_cs['hypothesis']) + ' [SEP]', valid_cs))\n",
        "test_sentences = list(map(lambda test_cs: '[CLS] ' + str(test_cs['premise']) + ' [SEP] ' + str(test_cs['hypothesis']) + ' [SEP]', test_cs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIJ6X1ghrXA_"
      },
      "outputs": [],
      "source": [
        "train_labels = train_cs['label']\n",
        "validation_labels = valid_cs['label']\n",
        "test_labels = test_cs['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMeFyIJxrYjd",
        "outputId": "2cac0397-bedc-4d8a-fd67-3a41d0538b3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] \uc6b0\ub9ac\ub294 \ub9c8\ub2f9\uc5d0\uc11c \ubb3c\ub180\uc774\ub3c4 \ud560 \uc218 \uc788\uc5c8\ub2e4 [SEP] \ub9c8\ub2f9\uc774 \ub113\uace0 \uc88b\uc558\ub2e4. [SEP]',\n",
              " '[CLS] \ubbf8\uad6d\uc758 \uc0c1\uc6d0\ubc95\uc0ac \uc704\uc6d0\ud68c\ub294 \ucf54\ubbf8 \uc804 \uad6d\uc7a5\uc5d0\uac8c \ub7ec\uc2dc\uc544 \ub300\uc120 \uac1c\uc785 \uad00\ub828 \uba54\ubaa8\ub97c \uc81c\ucd9c\ud558\ub3c4\ub85d \uc694\uad6c\ud558\uc600\uace0, \ubc31\uc545\uad00\ub3c4 \uad00\ub828 \ub179\ucde8\uae30\ub85d\uc744 \uc694\uad6c\ud558\uc600\ub2e4. [SEP] \ubbf8\uad6d\uc758 \uc0c1\uc6d0\ubc95\uc0ac \uc704\uc6d0\ud68c\ub294 \ubc31\uc545\uad00\uc5d0 \ub179\ucde8\uae30\ub85d \uc694\uad6c\ub294 \ud558\uc9c0 \uc54a\uc558\ub2e4. [SEP]',\n",
              " '[CLS] 10\uc6d4 29\uc77c \uae30\uc900, \uc804\uccb4 163\uac1c\uad6d\uc758 \ud68c\uc6d0\uad6d \uc911 104\uac1c\uad6d\uc774 \uc624\ucf58\uc870\uc774\uc6e8\uc54c\ub77c \ud6c4\ubcf4\ub97c \uc9c0\uc9c0\ud558\ub294 \uac83\uc73c\ub85c \uc54c\ub824\uc84c\ub2e4. [SEP] 10\uc6d4 29\uc77c \uae30\uc900 \ubaa8\ub4e0 \ud68c\uc6d0\uad6d\uc774 \uc624\ucf58\uc870\uc774\uc6e8\uc54c\ub77c \ud6c4\ubcf4\ub97c \uc9c0\uc9c0\ud558\ub294 \uac83\uc73c\ub85c \uc54c\ub824\uc84c\ub2e4. [SEP]',\n",
              " '[CLS] \uc601\ud654\ubcf4\ub294\ub0b4\ub0b4 \uc804\uac1c\uc640 \uc0c1\ud669\uc774 \uc9c0\ub8e8\ud574\uc11c \ubab0\uc785\ub3c4 \uc548\ub42c\uc2b5\ub2c8\ub2e4. [SEP] \uc804\uac1c\uc640 \uc0c1\ud669\uc774 \uc9c0\ub8e8\ud574\uc11c \uc601\ud654 \ubcf4\ub294 \ub0b4\ub0b4 \ubab0\uc785\uc774 \uc548\ub410\uc2b5\ub2c8\ub2e4. [SEP]',\n",
              " '[CLS] \uccad\uc18c\ub144\ub4e4\uc774 \uc9c1\uc811 \uac74\uc758\ud574 \uc798\ubabb\ub41c \ud45c\uae30\ub97c \uc2dc\uc815\ud558\uac8c \ud588\uace0, \uc815\ubd80\ub9cc\uc758 \uc5ed\ud560\uc774 \uc544\ub2cc \ub300\ud55c\ubbfc\uad6d \uad6d\ubbfc \ub204\uad6c\ub098 \ubbfc\uac04\uc678\uad50\uad00\uc774 \ub420 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc92c\uc2b5\ub2c8\ub2e4. [SEP] \uccad\uc18c\ub144\ub4e4\uc758 \ud65c\ub3d9\uc73c\ub85c \uc778\ud574 \ub9ce\uc740 \uc0ac\ub78c\ub4e4\uc774 \ubbfc\uac04\uc678\uad50\uad00\uc5d0 \uad00\uc2ec\uc744 \uac00\uc9c0\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4. [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "validation_sentences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB36uNAprqpy",
        "outputId": "1e9d0d16-b7de-4483-b2c9-4e1808dc3370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 2, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "validation_labels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCsmRkSzbVhS"
      },
      "source": [
        "## BERT \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc774\uc6a9\ud55c \uc804\ucc98\ub9ac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKYP2VNkR-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "d3b8180c9cbd4f83a7823d0d2b3e51d6",
            "712030fe289c426091849359edba4e83",
            "6c05e6bbd7ff448787023512e5875077",
            "2227149223624d4da7224b36c5cf3a83",
            "467f4cfdcba34002b43bddde3e9dad6d",
            "12f6221611fd40938336e066a4bcb42f",
            "f83f60ab5c304326bda01cb36db00159",
            "247d207702764207b12a0b6e343185fa",
            "10d2bfddfbf34fd2bff8c842b449dff0",
            "7efc80b9f8b7467fb07aa8051019a91d",
            "91200448a0e14618842923761b0fd054",
            "62027391c71141be98f7ebbdcfe7e502",
            "eec600e5f3b746c4b47be10f7332991e",
            "174abedc2c994edfa87324a193c0fccd",
            "827402ad62134bf1bcff5f0f74afc9c9",
            "75c0e34d0e2b417a8d0f9558715c143d",
            "50d299f056d745f286b01f244c89aef6",
            "19263c8b6807461e8a61b1863555c989",
            "e65e3473c72541ec88b6daf749d3b8ad",
            "77ce1e65ff904d258a1925c4baf5354f",
            "275f635c57744a77ac99a10a8a9eed51",
            "764afeb75abf478a9bc2444288e18a0d",
            "2d130a54d2604ba99fb333c27478ca88",
            "b291a079203f47fcae7a30903a1a8ba8",
            "fc98626b68b841e1ab5ced70b1089dac",
            "4cb122df07f64be5aa73ba76f6409aa6",
            "da96ee95e0c54c09b8dc52ee88afa612",
            "f7627dbb8ca14d5085fbbc0160e3c536",
            "402978055efc44e9a67d9cd05ce3db4b",
            "ceb7fe2a78d6410f8dfbcb93d641c955",
            "5c95fd8d34844fc280ff64e4a706328e",
            "5d082db05ae6423aae17dff804db368c",
            "7f7a35279be248d8bdff4d7d9ccb5665",
            "9ca2453450f144488d54d847099e7108",
            "fe3d9a4eaf3740389183aea01b72cea4",
            "ba34e8993089429587971d40ef39e177",
            "f146d7a49e784c1fbe05dda1665215bb",
            "4552de139f4a4988b633bb1075849dc0",
            "3dff780c5a994f3c8cc65f89f729d704",
            "922bee7dbddd4c338cf8215fe037faac",
            "4f09a2e198ff4f8eb960636dc1ea0300",
            "a919995fd89c4a9ba724bb0ad8a5efbd",
            "cc756873f478450c840dae4ea515e315",
            "69b194f071db421380395b8a9565622c",
            "31ffbebd645c498791252ea86c09ea45",
            "b74337f2bed646dd81c0b29b6b02b640",
            "82ea48dacc6e40fb95fc161799a8be14",
            "5754a62ade3e4203be6e490ead2b0612",
            "7e741e30b9994b9a9bdc973caa728789",
            "424af457df2f4131a319ca816e0f1599",
            "2ee3ee7a858b4921bd38ac05c0137a44",
            "c2b90e516adf48ab9b9e1689a61c0a8f",
            "8cf48deeca764fab9f9b92aabeadc1b4",
            "bc9076ce57d54393946bcbb78a9bcf29",
            "7144615c497c4df9bb68b735db2b6bf1"
          ]
        },
        "outputId": "c8ea5ee1-3bd1-4206-8731-7f2a919a10db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3b8180c9cbd4f83a7823d0d2b3e51d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62027391c71141be98f7ebbdcfe7e502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d130a54d2604ba99fb333c27478ca88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ca2453450f144488d54d847099e7108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ffbebd645c498791252ea86c09ea45"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# \ud55c\uad6d\uc5b4 BERT \uc911 \ud558\ub098\uc778 'klue/bert-base'\ub97c \uc0ac\uc6a9.\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize('\uc548\ub155\ud558\uc138\uc694. \uc790\uc5f0\uc5b4 \ucc98\ub9ac\ub97c \ubc30\uc6b8\uac70\uc5d0\uc694.')\n",
        "input_id = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "print('\ud1a0\ud070\ud654 \ub41c \ubb38\uc7a5 :', tokenized_text)\n",
        "print('\uc815\uc218 \uc778\ucf54\ub529 \ub41c \ubb38\uc7a5 :', input_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG9ImP-kNZEg",
        "outputId": "08371c61-d568-4620-d4d4-8838974d1cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud1a0\ud070\ud654 \ub41c \ubb38\uc7a5 : ['\uc548\ub155', '##\ud558', '##\uc138\uc694', '.', '\uc790\uc5f0', '##\uc5b4', '\ucc98\ub9ac', '##\ub97c', '\ubc30\uc6b8', '##\uac70', '##\uc5d0', '##\uc694', '.']\n",
            "\uc815\uc218 \uc778\ucf54\ub529 \ub41c \ubb38\uc7a5 : [5891, 2205, 5971, 18, 3941, 2051, 4211, 2138, 9402, 2180, 2170, 2182, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz7UtTLir4vI"
      },
      "outputs": [],
      "source": [
        "# \ucd5c\ub300 \uae38\uc774\ub294 128\n",
        "max_len = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels, max_len):\n",
        "  # \uc815\uc218 \uc778\ucf54\ub529 \uacfc\uc815. \uac01 \ud14d\uc2a4\ud2b8\ub97c \ud1a0\ud070\ud654\ud55c \ud6c4\uc5d0 Vocabulary\uc5d0 \ub9f5\ud551\ub418\ub294 \uc815\uc218 \uc2dc\ud000\uc2a4\ub85c \ubcc0\ud658\ud55c\ub2e4.\n",
        "  # ex) ['\uc548\ub155\ud558\uc138\uc694'] ==> ['\uc548', '\ub155', '\ud558\uc138\uc694'] ==> [231, 52, 45]\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "  # pad_sequences\ub294 \ud328\ub529\uc744 \uc704\ud55c \ubaa8\ub4c8. \uc8fc\uc5b4\uc9c4 \ucd5c\ub300 \uae38\uc774\ub97c \uc704\ud574\uc11c \ub4a4\uc5d0\uc11c 0\uc73c\ub85c \ucc44\uc6cc\uc900\ub2e4.\n",
        "  # ex) [231, 52, 45] ==> [231, 52, 45, 0, 0, 0]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  # \uc2e4\uc81c \ud1a0\ud070 \uc704\uce58\uc5d0\ub294 1, \ud328\ub529 \ud1a0\ud070 \uc704\uce58\uc5d0\ub294 0\uc744 \ub123\uc740 \ub9ac\uc2a4\ud2b8\uc778 \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c \uc81c\uc791.\n",
        "  # \uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc\uac00 [231, 52, 45, 0, 0, 0]\uc774 \uc788\ub2e4\uba74 231, 52, 45\ub294 \uc2e4\uc81c \ud1a0\ud070\uc774\uace0 0\uc740 \ud328\ub529 \ud1a0\ud070\uc774\ubbc0\ub85c\n",
        "  # \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c\ub294 [1, 1, 1, 0, 0, 0]\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtZR6CCnr6UZ"
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5 \ub370\uc774\ud130, \uac80\uc99d \ub370\uc774\ud130, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c\n",
        "# \uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc, \ub808\uc774\ube14, \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c\ub97c \uac01\uac01 inputs, labels, masks\uc5d0 \uc800\uc7a5.\n",
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels, max_len)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels, max_len)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "57E6BeDzsNOn",
        "outputId": "69138cdb-7197-467d-d2fc-41f459180728"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer.decode([2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y9h5E-HrsHd0",
        "outputId": "6b8bb505-b0ba-4b91-890e-ccb5b4d3f7bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.decode([3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjrQxrX4sC_t",
        "outputId": "bb798021-b621-44b9-fa69-95fc6889435a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc: tensor([    2, 25313,  2377,  2031,  2073, 20812,  2116,  1513,  2259,  1129,\n",
            "        24094, 20812, 27135,  9753,  2052,  3662, 11800,    18,     3,  3711,\n",
            "         1129, 27135,  2119,  9753,  2073,  5040,  3598,  3606,    18,     3,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "--------------------\n",
            "\uc6d0\ubcf8 \ubb38\uc7a5 \ubcf5\uc6d0 \uacb0\uacfc: [CLS] \ud761\uc5f0\uc790\ubd84\ub4e4\uc740 \ubc1c\ucf54\ub2c8\uac00 \uc788\ub294 \ubc29\uc774\uba74 \ubc1c\ucf54\ub2c8\uc5d0\uc11c \ud761\uc5f0\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. [SEP] \uc5b4\ub5a4 \ubc29\uc5d0\uc11c\ub3c4 \ud761\uc5f0\uc740 \uae08\uc9c0\ub429\ub2c8\ub2e4. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "--------------------\n",
            "\uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "--------------------\n",
            "\uc0d8\ud50c\uc758 \uae38\uc774: 128\n",
            "--------------------\n",
            "\ub808\uc774\ube14: tensor(2)\n"
          ]
        }
      ],
      "source": [
        "print('\uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc:', test_inputs[0])\n",
        "print('-' * 20)\n",
        "print('\uc6d0\ubcf8 \ubb38\uc7a5 \ubcf5\uc6d0 \uacb0\uacfc:', tokenizer.decode(test_inputs[0]))\n",
        "print('-' * 20)\n",
        "print('\uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c:', test_masks[0])\n",
        "print('-' * 20)\n",
        "print('\uc0d8\ud50c\uc758 \uae38\uc774:', len(test_inputs[0]))\n",
        "print('-' * 20)\n",
        "print('\ub808\uc774\ube14:', test_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ub370\uc774\ud130 \ubc30\uce58\ud654"
      ],
      "metadata": {
        "id": "6qXGkbHZdG1v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKIP4SwXqALa"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "sZRgSwd_crnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "8ldlDrMadMuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "1246de57-1fca-46e9-f6c9-59c8ea0f4605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30: 22498\n",
            "\uac80\uc99d \ub370\uc774\ud130\uc758 \ud06c\uae30: 2500\n",
            "\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \ud06c\uae30: 3000\n"
          ]
        }
      ],
      "source": [
        "print('\ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(train_labels))\n",
        "print('\uac80\uc99d \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(validation_labels))\n",
        "print('\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9moVKInibnca"
      },
      "source": [
        "## GPU\uac00 \uc815\uc0c1 \uc14b\ud305\ub418\uc5c8\ub294\uc9c0 \ud655\uc778.  \n",
        "Colab\uc5d0\uc11c GPU\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc124\uc815\uc774 \ub418\uc5b4\uc788\uc5b4\uc57c\ub9cc \ud569\ub2c8\ub2e4.  \n",
        "\n",
        "* \ub7f0\ud0c0\uc784 > \ub7f0\ud0c0\uc784 \uc720\ud615 \ubcc0\uacbd > \ud558\ub4dc\uc6e8\uc5b4 \uac00\uc18d\uae30 > 'GPU' \uc120\ud0dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "ca65f17a-d75d-4d0b-b387-3d253bdf723a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dryCfxh4btMS"
      },
      "source": [
        "## \ubaa8\ub378 \ub85c\ub4dc\ud558\uae30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TPO6di_YhGV",
        "outputId": "a25e2039-1489-48b2-ad01-49da6ae0c545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqqbD-tBcehO"
      },
      "source": [
        "## \ubaa8\ub378 \ud559\uc2b5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO_GNYxCSYfq",
        "outputId": "4a82e937-03cc-4e1b-e13d-99f72340ceef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# \uc635\ud2f0\ub9c8\uc774\uc800 \uc120\ud0dd\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4BGSrTx243"
      },
      "outputs": [],
      "source": [
        "# \uba87 \ubc88\uc758 \uc5d0\ud3ec\ud06c(\uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ud559\uc2b5 \ud69f\uc218)\ub97c \ud560 \uac83\uc778\uc9c0 \uc120\ud0dd\n",
        "epochs = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "FGDf4qO26Ord"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(predictions, labels):\n",
        "    # predictions: \ubaa8\ub378\uc774 \uc608\uce21\ud55c \uacb0\uacfc\uac12\ub4e4\uc758 \ub9ac\uc2a4\ud2b8 \ub610\ub294 \ubc30\uc5f4\n",
        "    # labels: \uc2e4\uc81c \uc815\ub2f5 \ub808\uc774\ube14\ub4e4\uc758 \ub9ac\uc2a4\ud2b8 \ub610\ub294 \ubc30\uc5f4\n",
        "\n",
        "    # \uc608\uce21\uac12\uacfc \uc2e4\uc81c \ub808\uc774\ube14\uc744 \ubcc4\ub3c4\uc758 \ubcc0\uc218\uc5d0 \ud560\ub2f9\n",
        "    y_pred = predictions\n",
        "    y_true = labels\n",
        "\n",
        "    # \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba54\ud2b8\ub9ad\ub4e4\uc744 \uacc4\uc0b0\n",
        "\n",
        "    # \uc815\ud655\ub3c4 (Accuracy)\n",
        "    # \uc804\uccb4 \uc608\uce21 \uc911\uc5d0\uc11c \uc62c\ubc14\ub974\uac8c \uc608\uce21\ud55c \ube44\uc728\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # \ub9e4\ud06c\ub85c \ud3c9\uade0 F1 \uc810\uc218 (Macro-averaged F1 Score)\n",
        "    # \ud074\ub798\uc2a4\ubcc4\ub85c F1 \uc810\uc218\ub97c \uacc4\uc0b0\ud55c \ud6c4, \uadf8 \ud3c9\uade0\uc744 \uad6c\ud568\n",
        "    # zero_division=0 \uc635\uc158\uc740 \ubd84\ubaa8\uac00 0\uc77c \uacbd\uc6b0 0\uc744 \ubc18\ud658\ud558\ub3c4\ub85d \uc124\uc815\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # \ub9c8\uc774\ud06c\ub85c \ud3c9\uade0 F1 \uc810\uc218 (Micro-averaged F1 Score)\n",
        "    # \uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \ub2e8\uc77c F1 \uc810\uc218\ub97c \uacc4\uc0b0\n",
        "    # \ud074\ub798\uc2a4 \ubd88\uade0\ud615\uc774 \uc2ec\ud55c \uacbd\uc6b0\uc5d0 \uc801\ud569\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "\n",
        "    # \uac00\uc911 \ud3c9\uade0 F1 \uc810\uc218 (Weighted-averaged F1 Score)\n",
        "    # \uac01 \ud074\ub798\uc2a4\uc758 F1 \uc810\uc218\uc5d0 \ud574\ub2f9 \ud074\ub798\uc2a4\uc758 \uc0d8\ud50c \uc218\ub97c \uac00\uc911\uce58\ub85c \uacf1\ud55c \ud6c4 \ud3c9\uade0\uc744 \uad6c\ud568\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # \uacc4\uc0b0\ub41c \uba54\ud2b8\ub9ad \uacb0\uacfc\ub97c \ub515\uc154\ub108\ub9ac \ud615\ud0dc\ub85c \ub9ac\ud134\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average}\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "3k5hl95K6Rlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_dataloader, optimizer, device):\n",
        "    \"\"\"\n",
        "    \ud558\ub098\uc758 \uc5d0\ud3ec\ud06c \ub3d9\uc548 \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\ub294 \ud568\uc218\uc785\ub2c8\ub2e4.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): \ud559\uc2b5\uc2dc\ud0ac \ubaa8\ub378 \uac1d\uccb4.\n",
        "    train_dataloader (torch.utils.data.DataLoader): \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc758 DataLoader.\n",
        "    optimizer (torch.optim.Optimizer): \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998\uc744 \uad6c\ud604\ud558\ub294 \uac1d\uccb4.\n",
        "    device (torch.device): \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud560 \uc7a5\uce58(CPU \ub610\ub294 CUDA).\n",
        "\n",
        "    Returns:\n",
        "    float: \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4\uac12.\n",
        "    \"\"\"\n",
        "\n",
        "    total_train_loss = 0  # \ud559\uc2b5 \uc190\uc2e4\uc744 \ub204\uc801\ud560 \ubcc0\uc218 \ucd08\uae30\ud654\n",
        "    model.train()  # \ubaa8\ub378\uc744 \ud559\uc2b5 \ubaa8\ub4dc\ub85c \uc124\uc815\n",
        "\n",
        "    # \ud559\uc2b5 \ub370\uc774\ud130\ub85c\ub354\ub97c \uc21c\ud68c\ud558\uba70 \ubc30\uce58 \ub2e8\uc704\ub85c \ud559\uc2b5\n",
        "    for step, batch in tqdm(enumerate(train_dataloader), desc=\"Training Batch\"):\n",
        "        batch = tuple(t.to(device) for t in batch)  # DataLoader\uc5d0\uc11c \ubc30\uce58\ub97c \ubc1b\uc544 \uac01 \ud150\uc11c\ub97c \uc9c0\uc815\ub41c \uc7a5\uce58\ub85c \uc774\ub3d9\n",
        "        b_input_ids, b_input_mask, b_labels = batch  # \ubc30\uce58\uc5d0\uc11c \uc785\ub825 ID, \ub9c8\uc2a4\ud06c, \ub77c\ubca8 \ucd94\ucd9c\n",
        "\n",
        "        # \ubaa8\ub378\uc5d0 \ubc30\uce58\ub97c \uc804\ub2ec\ud558\uc5ec \uc190\uc2e4\uac12 \uacc4\uc0b0\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        # \uc190\uc2e4\uac12 \ucd94\ucd9c\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()  # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n",
        "        loss.backward()  # \uc5ed\uc804\ud30c\ub97c \ud1b5\ud574 \uadf8\ub798\ub514\uc5b8\ud2b8 \uacc4\uc0b0\n",
        "        optimizer.step()  # \ub9e4\uac1c\ubcc0\uc218 \uc5c5\ub370\uc774\ud2b8\n",
        "\n",
        "        total_train_loss += loss.item()  # \ucd1d \uc190\uc2e4\uc5d0 \ub354\ud568\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)  # \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4 \uacc4\uc0b0\n",
        "\n",
        "    return avg_train_loss  # \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4 \ubc18\ud658"
      ],
      "metadata": {
        "id": "fVMCWtsp6S_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, validation_dataloader, device):\n",
        "    \"\"\"\n",
        "    \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac80\uc99d \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ud3c9\uac00\ub97c \uc218\ud589\ud558\ub294 \ud568\uc218\uc785\ub2c8\ub2e4.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): \ud3c9\uac00\ud560 \ubaa8\ub378 \uac1d\uccb4.\n",
        "    validation_dataloader (torch.utils.data.DataLoader): \uac80\uc99d \ub370\uc774\ud130\uc14b\uc758 DataLoader.\n",
        "    device (torch.device): \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ud560 \uc7a5\uce58(CPU \ub610\ub294 CUDA).\n",
        "\n",
        "    Returns:\n",
        "    float: \ud3c9\uade0 \uac80\uc99d \uc190\uc2e4\uac12.\n",
        "    dict: \ub2e4\uc591\ud55c \ud3c9\uac00 \uc9c0\ud45c(metrics)\uc5d0 \ub300\ud55c \uac12\ub4e4\uc744 \ub2f4\uc740 \uc0ac\uc804.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # \ubaa8\ub378\uc744 \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\n",
        "\n",
        "    total_eval_loss = 0  # \uac80\uc99d \uc190\uc2e4\uc744 \ub204\uc801\ud560 \ubcc0\uc218 \ucd08\uae30\ud654\n",
        "    predictions, true_labels = [], []  # \uc608\uce21\uac12\uacfc \uc2e4\uc81c \ub77c\ubca8\uac12\uc744 \uc800\uc7a5\ud560 \ub9ac\uc2a4\ud2b8 \ucd08\uae30\ud654\n",
        "\n",
        "    # \uac80\uc99d \ub370\uc774\ud130\ub85c\ub354\ub97c \uc21c\ud68c\ud558\uba70 \ubc30\uce58 \ub2e8\uc704\ub85c \ud3c9\uac00\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)  # \ubc30\uce58 \ub370\uc774\ud130\ub97c \ub514\ubc14\uc774\uc2a4\ub85c \uc774\ub3d9\n",
        "        b_input_ids, b_input_mask, b_labels = batch  # \ubc30\uce58\uc5d0\uc11c \uc785\ub825 ID, \ub9c8\uc2a4\ud06c, \ub77c\ubca8 \ucd94\ucd9c\n",
        "\n",
        "        with torch.no_grad():  # \uadf8\ub798\ub514\uc5b8\ud2b8 \uacc4\uc0b0\uc744 \uc218\ud589\ud558\uc9c0 \uc54a\uc74c\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        # \ubaa8\ub378 \ucd9c\ub825\uc5d0\uc11c \uc190\uc2e4\uac12 \ucd94\ucd9c (\uc218\uc815\ub41c \ubd80\ubd84)\n",
        "        if outputs.loss is not None:\n",
        "            loss = outputs.loss\n",
        "            total_eval_loss += loss.item()  # \ucd1d \uc190\uc2e4\uc5d0 \ub354\ud568\n",
        "\n",
        "        logits = outputs.logits.detach().cpu().numpy()  # \ubaa8\ub378 \uc608\uce21\uac12(\ub85c\uc9d3)\uc744 numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "        label_ids = b_labels.to('cpu').numpy()  # \uc2e4\uc81c \ub77c\ubca8\uac12\uc744 numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "\n",
        "        # 3\uac1c\uc758 \uac12 \uc911 \uac00\uc7a5 \ud070 \uac12\uc744 \uc608\uce21\ud55c \uc778\ub371\uc2a4\ub85c \uacb0\uc815 (\uc608\uc2dc: logits = [3.513, -0.309, -2.111] ==> \uc608\uce21: 0)\n",
        "        predictions.extend(np.argmax(logits, axis=1).flatten()) # \uc608\uce21\ub41c \ud074\ub798\uc2a4\ub97c \ub9ac\uc2a4\ud2b8\uc5d0 \ucd94\uac00\n",
        "        true_labels.extend(label_ids.flatten()) # \uc2e4\uc81c \ub808\uc774\ube14 \uac12\uc744 \ub9ac\uc2a4\ud2b8\uc5d0 \ucd94\uac00\n",
        "\n",
        "    eval_metrics = metrics(predictions, true_labels)\n",
        "\n",
        "    return total_eval_loss / len(validation_dataloader), eval_metrics"
      ],
      "metadata": {
        "id": "yARSy46x6XHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \ucd5c\uc18c \uac80\uc99d \uc190\uc2e4 \ucd08\uae30\ud654\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "# \uba54\uc778 \ud559\uc2b5 & \ud3c9\uac00 \ub8e8\ud504\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    # \ud559\uc2b5 \ub2e8\uacc4\n",
        "    train_epoch(model, train_dataloader, optimizer, device)\n",
        "\n",
        "    print(\"\\nRunning Validation...\")\n",
        "    # \uac80\uc99d \ub2e8\uacc4\n",
        "    avg_val_loss, eval_metrics = evaluate(model, validation_dataloader, device)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
        "    print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
        "    print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
        "    print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n",
        "\n",
        "    # \uac80\uc99d \uc190\uc2e4\uc774 \ud604\uc7ac\uae4c\uc9c0\uc758 \ucd5c\uc18c\uac12\ubcf4\ub2e4 \uc791\uc740 \uacbd\uc6b0 \uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\n",
        "    if avg_val_loss < min_val_loss:\n",
        "        print(f\"Validation loss decreased ({min_val_loss:.2f} --> {avg_val_loss:.2f}).  Saving model ...\")\n",
        "        # \ubca0\uc2a4\ud2b8 \ubaa8\ub378 \uc800\uc7a5\n",
        "        torch.save(model.state_dict(), 'model_checkpoint.pt')\n",
        "        # \ucd5c\uc18c \uac80\uc99d \uc190\uc2e4 \uc5c5\ub370\uc774\ud2b8\n",
        "        min_val_loss = avg_val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-HD4Dko6cfY",
        "outputId": "dadd8971-f4cb-4649-b9c8-930c93719c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 704it [01:51,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.82\n",
            "  F1 Macro: 0.82\n",
            "  F1 Micro: 0.82\n",
            "  F1 Weighted: 0.82\n",
            "Validation loss decreased (inf --> 0.47).  Saving model ...\n",
            "======== Epoch 2 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 704it [01:51,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.84\n",
            "  F1 Macro: 0.84\n",
            "  F1 Micro: 0.84\n",
            "  F1 Weighted: 0.84\n",
            "Validation loss decreased (0.47 --> 0.44).  Saving model ...\n",
            "======== Epoch 3 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 704it [01:51,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.82\n",
            "  F1 Macro: 0.82\n",
            "  F1 Micro: 0.82\n",
            "  F1 Weighted: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd_MC6kOc8JV"
      },
      "source": [
        "## \ubaa8\ub378 \uc800\uc7a5\uacfc \ub85c\ub4dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dEYcwOptN11n",
        "outputId": "7c336da4-0956-4648-9286-edd76f2d6739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgxXrIlEGJyL",
        "outputId": "3a6f389b-364e-4b0d-b331-a6b29d85ae78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 432208\n",
            "drwxr-xr-x 1 root root      4096 Feb 11 16:47 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root      4096 Feb 11 16:41 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root      4096 Feb  8 14:20 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root 442562069 Feb 11 17:03 model_checkpoint.pt\n",
            "drwxr-xr-x 1 root root      4096 Feb  8 14:21 \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "b04a322b-bae7-44ac-9048-a1ca31a0f477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# \ubca0\uc2a4\ud2b8 \ubaa8\ub378 \ub85c\ub4dc\n",
        "model.load_state_dict(torch.load(\"model_checkpoint.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qSHpWCdOiPk"
      },
      "source": [
        "# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ud3c9\uac00"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_val_loss, eval_metrics = evaluate(model, test_dataloader, device)\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
        "print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
        "print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
        "print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMryr1HbItQs",
        "outputId": "b59dbff1-400b-44cd-bc4b-14612a471107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Loss: 0.52\n",
            "  Accuracy: 0.79\n",
            "  F1 Macro: 0.79\n",
            "  F1 Micro: 0.79\n",
            "  F1 Weighted: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC0ZwCb1OeBd"
      },
      "source": [
        "# \uc608\uce21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJUifpTANkUz"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KIEQnGPkM-",
        "outputId": "1a412b7b-5001-4e97-8f97-6af6e45c9220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512,\n",
        "                return_all_scores=True, function_to_apply='softmax')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"text\" : \"\ud761\uc5f0\uc790\ubd84\ub4e4\uc740 \ubc1c\ucf54\ub2c8\uac00 \uc788\ub294 \ubc29\uc774\uba74 \ubc1c\ucf54\ub2c8\uc5d0\uc11c \ud761\uc5f0\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.\", \"text_pair\" : \"\uc5b4\ub5a4 \ubc29\uc5d0\uc11c\ub3c4 \ud761\uc5f0\uc740 \uae08\uc9c0\ub429\ub2c8\ub2e4.\"}"
      ],
      "metadata": {
        "id": "d5SMltgENYNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmk18kVUQVwV",
        "outputId": "2d4515ba-c5ac-43b5-b2b6-b6ecbf27d0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.012474408373236656}, {'label': 'LABEL_1', 'score': 0.05696354806423187}, {'label': 'LABEL_2', 'score': 0.9305620193481445}]]\n"
          ]
        }
      ],
      "source": [
        "result = pipe([inputs])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_all_scores\ub97c \uc81c\uac70\ud558\uba74 \uc815\ub2f5\uc73c\ub85c \ud655\uc2e0\ud558\ub294 \ub808\uc774\ube14\ub9cc \ub9ac\ud134\ud569\ub2c8\ub2e4."
      ],
      "metadata": {
        "id": "3Lcf-Bf-Pk6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# return_all_scores \uc81c\uac70\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, function_to_apply='softmax')"
      ],
      "metadata": {
        "id": "wcGx21K8Owgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe([inputs])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jO1b-fmO0Yw",
        "outputId": "7a5aef51-7a1e-4f5c-ddba-8f8807346c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_2', 'score': 0.9305620193481445}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-xQGKk4QZMn"
      },
      "outputs": [],
      "source": [
        "label_dict = {'LABEL_0' : '\uc5bd\ud798', 'LABEL_1' : '\uc911\ub9bd', 'LABEL_2' : '\ubaa8\uc21c'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO2VS0j2Q3CG"
      },
      "outputs": [],
      "source": [
        "def prediction(sent1, sent2):\n",
        "  text = {\"text\" : sent1, \"text_pair\" : sent2}\n",
        "  result = pipe(text)\n",
        "  return [label_dict[result['label']]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = \"\ud761\uc5f0\uc790\ubd84\ub4e4\uc740 \ubc1c\ucf54\ub2c8\uac00 \uc788\ub294 \ubc29\uc774\uba74 \ubc1c\ucf54\ub2c8\uc5d0\uc11c \ud761\uc5f0\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.\"\n",
        "sent2 = \"\uc5b4\ub5a4 \ubc29\uc5d0\uc11c\ub3c4 \ud761\uc5f0\uc740 \uae08\uc9c0\ub429\ub2c8\ub2e4.\""
      ],
      "metadata": {
        "id": "RKI-kXQrOZh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onQ7KRNKRBKm",
        "outputId": "342234e2-9a5c-4feb-cf3f-1ab23c5b0e1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\ubaa8\uc21c']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "prediction(sent1, sent2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = \"\uc800\ub294, \uadf8\ub0e5 \uc54c\uc544\ub0b4\ub824\uace0 \uac70\uae30 \uc788\uc5c8\uc5b4\uc694.\"\n",
        "sent2 = \"\ub098\ub294 \ub3c8\uc774 \uc5b4\ub514\ub85c \uac14\ub294\uc9c0 \uc774\ud574\ud558\ub824\uace0 \ud588\uc5b4\uc694.\""
      ],
      "metadata": {
        "id": "ciE0U5hgPDbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(sent1, sent2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msP2ghuAPGq1",
        "outputId": "b90f057b-1ca8-4a76-a172-3270de723f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\uc911\ub9bd']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = \"\uc800\ub294 \uadf8\uac83\uc744 \uc774\ud574\ud558\ub824\uace0 \uac70\uae30 \uc788\uc5c8\uc5b4\uc694.\"\n",
        "sent2 = \"\uc800\ub294 \uc774\ud574\ud558\ub824\uace0 \ub178\ub825\ud558\uace0 \uc788\uc5c8\uc5b4\uc694.\""
      ],
      "metadata": {
        "id": "ihuqt-6WPHPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(sent1, sent2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLjLgIzPILM",
        "outputId": "7411151e-60ca-4391-c1c3-07a66569def6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\uc5bd\ud798']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}