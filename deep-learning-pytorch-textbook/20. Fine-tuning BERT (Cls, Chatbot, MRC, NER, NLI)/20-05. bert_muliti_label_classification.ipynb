{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "References : https://github.com/adlnlp/K-MHaS"
      ],
      "metadata": {
        "id": "2idJX7pbRgsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \ud55c\uad6d\uc5b4 \ud610\uc624 \ubc1c\uc5b8 \ub2e4\uc911 \ub808\uc774\ube14 \ubd84\ub958 : K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066a19c7-3279-4a53-c0e6-5faa81abd2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ub370\uc774\ud130\uc14b \ub85c\ub4dc \ubc0f \uad6c\uc870 \ud655\uc778"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "59e35c1503434144a9f81a027d1d6529",
            "2d5de23f7af744bea282ea5a0aefa2bd",
            "82afed99c3db439abb2ab229d0f885e5",
            "692c1c94494043bea7b4e26908185b8e",
            "c4d36b671e864c188047cac43e087bce",
            "4565728982a24e2d9e0ae02f03883148",
            "eb6c070ee4704ae59386224f0f97bdcc",
            "fdbcbfba87ae487dbfc4a36bd00d6cdc",
            "08f297136e6944419dd886e6f07195fb",
            "9f1e91b63b1645d8b94489e267d72df0",
            "5628bd17c6de4dc8969e92cacd5960a6",
            "74425267792e48efbe1ef0895ac781b6",
            "857c408b1e8547f983d50c9d0a0e2229",
            "47695c2d140c4892905db256e697fa9b",
            "328270e045434d5587774e03e78e7386",
            "d083d179253746dc95407e44f6702e62",
            "08d4d6925d894bcc9d9498a769bc8044",
            "54ef909a88cd493f92244dd45d21cff8",
            "756da5a5d6644929846589825749f96c",
            "195d89a457584afc9804153110310dcd",
            "02980d506cd9494493fc140038d22176",
            "de58d817bf914f82889b126b4636086d",
            "f85449d69ddc47228d336b0327791075",
            "3794645be7044a2fa415d0c98d2fbfbb",
            "66ddd28830bf49e19a242aff2abf6800",
            "60ba6a77a0cb484c95d60be3e1f74a74",
            "93a1dd7f8e2942e1917cb9f8d59070c8",
            "0af03ac7b4bb45e2817c74bf3ec05c5f",
            "6b8afbf7d76342a1a00e8624cfb8d4b0",
            "0f6db897508949e98a152c803f896b77",
            "19eea6ab19c542c3b16f69e6d8d4abd9",
            "2d72387e1a364a1294203c444b83ab7b",
            "e53159490c554d3fa0c5754474319ea9",
            "899d7a2857c2498a9312e9c93f8affae",
            "5e474893be004889879a8dc4b6cff9e0",
            "6adf4f58f3fc4238aedeb880d1b7734b",
            "cc023b9472f84101af1b1e57b3e43147",
            "e0b0d23091354a3981ecfac2c9b653bc",
            "57c73bec80ef44df986e58c373c53f01",
            "f4791f5472a840e38087c3fa0c5cb3cb",
            "f19d40b549ea42ae9ccdcc25a2cbd5fb",
            "8bbe9e74db8b4495b3e0f3736d4efafa",
            "47ebdbab427941c3a6b0ee3a737811d8",
            "585b6f01b0064dbb88149cbd3bc53c16",
            "a489ce6a2533479a94faeb0766e48da1",
            "492184291a2c478995fdc948d2e56156",
            "9029ca76bdeb4be5b30d7ae22b683ff4",
            "bdbe8c3fa5124a84bf36bcf7a14b2de4",
            "b8791d926f05411a934fe4ab9ddb787a",
            "73de50cd3aaa4fc097fbdfcfe0a46908",
            "a7d365826b2543b4aed1113979d7af5a",
            "37d6de9602474af1b040f30cd3e11fe8",
            "0612cb03ecf048d8aec16d9a683bc4d1",
            "094716111de5448a93f8fc743d8a679d",
            "d487c8b87edc463da34200ecb8e17fb4",
            "ed33d205d7164d04ab25a0600d5e089c",
            "ae8e5c699b1645f9ab418c2cfb56d091",
            "4f73c3e896714014aca35f787de6b45c",
            "1e9a148fb61b415691a3ea5a18526fc4",
            "06c241a98d9f465786b3ac98c207b19f",
            "9f594d5e6fbd41c4891161dc0698989f",
            "2c741e36cfd649c78904033b16193a68",
            "595adf1fde5644e582fe90d7fac2541d",
            "b1e3e919f72f4be0b6c01efa5ad4702a",
            "15c585e31bab460284157cc0cbeff64b",
            "96cc9c5bf1eb47b78a0e325c0f5a4dc5"
          ]
        },
        "outputId": "b8dac146-d61a-4966-f5e4-3ac369612bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59e35c1503434144a9f81a027d1d6529"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74425267792e48efbe1ef0895ac781b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f85449d69ddc47228d336b0327791075"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "899d7a2857c2498a9312e9c93f8affae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a489ce6a2533479a94faeb0766e48da1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed33d205d7164d04ab25a0600d5e089c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "544a69ca-a335-4a64-a780-c6c523ca68cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "1e2e288e-f76c-4c70-ccc5-d0666bb3be54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "c3fdc5af-f522-43d3-a499-b9d48564c341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc14b\uc758 \ud06c\uae30 :', len(dataset['text']))\n",
        "print('\uccab\ubc88\uc9f8 \uc0d8\ud50c \ucd9c\ub825 :', dataset['text'][0])\n",
        "print('\uccab\ubc88\uc9f8 \uc0d8\ud50c\uc758 \ub808\uc774\ube14 \ucd9c\ub825 :', dataset['label'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joEjGyQtrfMP",
        "outputId": "f0505250-4744-41de-8808-259a27a0cb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc14b\uc758 \ud06c\uae30 : 21939\n",
            "\uccab\ubc88\uc9f8 \uc0d8\ud50c \ucd9c\ub825 : \uadf8\ub9cc\ud07c \uae38\uc608\ub974\ubaa8\uac00 \uc798\ud588\ub2e4\uace0 \ubcf4\uba74\ub418\uaca0\uc9c0 \uae30\ub300\ub418\ub124 \uc170\uc774\ud504 \uc624\ube0c \uc6cc\ud130\n",
            "\uccab\ubc88\uc9f8 \uc0d8\ud50c\uc758 \ub808\uc774\ube14 \ucd9c\ub825 : [8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- \ub370\uc774\ud130\uc14b\uc758 [\uae43\ud5c8\ube0c](https://github.com/adlnlp/K-MHaS)\ub85c\ubd80\ud130 \ud655\uc778\ud560 \uc218 \uc788\ub294 \uac01 \ub808\uc774\ube14\uc774 \uc758\ubbf8\ud558\ub294 \ubc14\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4. \ub808\uc774\ube14\uc740 0\ubd80\ud130 8\uae4c\uc9c0 \ucd1d 9\uac1c\uc758 \ub808\uc774\ube14\uc774 \uc874\uc7ac\ud569\ub2c8\ub2e4.\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin (\ucd9c\uc2e0\ucc28\ubcc4)\n",
        "          1: physical (\uc678\ubaa8\ucc28\ubcc4)\n",
        "          2: politics (\uc815\uce58\uc131\ud5a5\ucc28\ubcc4)\n",
        "          3: profanity (\ud610\uc624\uc695\uc124)\n",
        "          4: age (\uc5f0\ub839\ucc28\ubcc4)\n",
        "          5: gender (\uc131\ucc28\ubcc4)\n",
        "          6: race (\uc778\uc885\ucc28\ubcc4)\n",
        "          7: religion (\uc885\uad50\ucc28\ubcc4)\n",
        "          8: not_hate_speech (\ud610\uc624\uc544\ub2d8)"
      ],
      "metadata": {
        "id": "U5ZCUPgpsAca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\ub450\ubc88\uc9f8 \uc0d8\ud50c \ucd9c\ub825 :', dataset['text'][1])\n",
        "print('\ub450\ubc88\uc9f8 \uc0d8\ud50c\uc758 \ub808\uc774\ube14 \ucd9c\ub825 :', dataset['label'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feygo4AmsNNS",
        "outputId": "acdd7a12-82b1-4e39-eb63-f294718234c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ub450\ubc88\uc9f8 \uc0d8\ud50c \ucd9c\ub825 : \"1. 8\ub118\uc758 \ubb38\uc7ac\uc559\"\n",
            "\ub450\ubc88\uc9f8 \uc0d8\ud50c\uc758 \ub808\uc774\ube14 \ucd9c\ub825 : [2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ub370\uc774\ud130\uc14b \uc804\ucc98\ub9ac"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# BERT \uc0ac\uc6a9\uc744 \uc704\ud568\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# for padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# \uc804\ucc98\ub9ac \ubc0f \ud3c9\uac00 \uc9c0\ud45c\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \ud6c8\ub828 \ub370\uc774\ud130, \uac80\uc99d \ub370\uc774\ud130, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud569\ub2c8\ub2e4.\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \ud6c8\ub828 \ub370\uc774\ud130, \uac80\uc99d \ub370\uc774\ud130, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c `[CLS] \ubb38\uc7a5 [SEP]` \uad6c\uc870\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \uc815\ub2f5\uc778 \ub808\uc774\ube14\uc758 \uc704\uce58\uc5d0\ub294 1, \ub098\uba38\uc9c0 \uc704\uce58\uc5d0\ub294 0\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
        "# \ub808\uc774\ube14 \uc804\ucc98\ub9ac \uc608\uc2dc)\n",
        "# [8]    -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] : \uc758\ubbf8\uc801\uc73c\ub85c\ub294 [no, no, no, no, no, no, no, no, no, yes]\n",
        "# [2, 3] -> [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] : \uc758\ubbf8\uc801\uc73c\ub85c\ub294 [no, no, yes, yes, no, no, no, no, no, no]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "id": "B-xu24pnaxek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19316755-a608-4788-a7bd-7c63842a535b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] \uadf8\ub9cc\ud07c \uae38\uc608\ub974\ubaa8\uac00 \uc798\ud588\ub2e4\uace0 \ubcf4\uba74\ub418\uaca0\uc9c0 \uae30\ub300\ub418\ub124 \uc170\uc774\ud504 \uc624\ube0c \uc6cc\ud130 [SEP]',\n",
              " '[CLS] \"1. 8\ub118\uc758 \ubb38\uc7ac\uc559\" [SEP]',\n",
              " '[CLS] \"\ubb38\uc7ac\uc778 \uc815\uad8c\uc758 \ub0b4\ub85c\ub0a8\ubd88\uc740 \ud0c0\uc758 \ucd94\uc885\uc744 \ubd88\ud5c8\ud558\ub124. \uc790\ud55c\ub2f9 \uc695\ud560\uac70\ub9ac\ub3c4 \uc5c6\uc74c.\" [SEP]',\n",
              " '[CLS] \"\uc9f1\uac1c\ub4e4 \uc9c0\ub098\uac04 \uacf3\uc740 \ud3d0\ud5c8\ub41c\ub2e4 \u314b\u314b\" [SEP]',\n",
              " '[CLS] \uacf1\ucc3d\uc740 \uc790\uac08\uce58~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \uac01 \ub808\uc774\ube14\uc740 \uae30\uc874\uc5d0 [8], [2, 3], [2], [0], [8] \uc774\uc5c8\uc73c\uba70 \uc804\ucc98\ub9ac \ud6c4 \uc544\ub798\uc640 \uac19\uc774 \ubcc0\uacbd\ub428.\n",
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "6d3d6e1f-7072-4e48-9cb5-165e7107195c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc774\uc6a9\ud55c \uc804\ucc98\ub9ac"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \ud55c\uad6d\uc5b4 BERT \uc911 \ud558\ub098\uc778 'klue/bert-base'\ub97c \uc0ac\uc6a9.\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "ebfa5c16f6414b2db6f7c31085050d27",
            "fc0052542bac4e4abad4180c61ae1c5f",
            "2bec4f2b9a8646c8a0e52d8c9b36b6ee",
            "ba07e01abbdf4dce98b254018f5b214d",
            "33a9d7ad23894eafa692d64d115f1867",
            "3cfd9923e63e41aa984b78eb329b885b",
            "eab9ed4854a5483baaa8ba9ca1226334",
            "04d4fbad85674a57b2a91f3a4a05341d",
            "682af3a8625b41238d227e92ccae18d3",
            "a8d7ad1c9bdc4e818b2149809fe116b7",
            "94969c7ee24d46e79c60d3f51dfc15ee",
            "f57c649e718d42a98ef54d26d33189f0",
            "0e673e233b8c48d6817b63e3450f110b",
            "b813c289fa984fab9e7f97661f655b09",
            "af7d5dd41bd744a59f4b435134921028",
            "f0bfea0554b24b579f5f714eebccad46",
            "eb9d028960f9455f9844456844339e6f",
            "ee570e308a1a40a3a2531dc783bfc906",
            "2262903a175341be81794e83d5c75bea",
            "aa96179de3e54f15b081ab716c5ca1e4",
            "09c60c12ef1c4e299aa6d79d41e7d1d4",
            "34595344efb74e82a2aa372ce2aa845a",
            "82ed0a40ab8846b1b2f622d1de16e5df",
            "728006fc019b48bd8765a47b4f23e163",
            "5dde5598b8324177a5e0e4401700772c",
            "18863cbd4fb14c8c927a1e7d137c8c9c",
            "c29c83fb7dc649ada2f356c2a93c7600",
            "6cd50ada674e4814b8bdc2061811f8f7",
            "828c02e561794d399c06f2420f930a9e",
            "dbb2e8132e86494ba13f27df70b83220",
            "682630abc50b473cacabedcb3bf4e823",
            "d66b190e98164001b13038fed99c08a6",
            "9c98cc2a27324e30864c9490e0bdf91a",
            "0ca915f709454cc3afdc462afe3099f9",
            "df46e69cdffe49e88af5596874af0606",
            "7170ad222ac94e9baeda20e288b06165",
            "e4f29d3d8bf745e5bcd7d078ec606bad",
            "ba65436137284d88b4eb4832891fe277",
            "6e3c53742e264f4d90ec7ab6cedaed07",
            "24bcf5b332b94a5caae81144fe00d698",
            "781be0b713f84dae881d57e96de1db1b",
            "031b4cd1f3ea4a5483525bd6b124d1fa",
            "b19aa2a6192d44f08a37aa3d6653275d",
            "12bf35a5ea184ab58990e9f91ade516d",
            "51d5bfacb7814ca7bba4e9535d8f5a22",
            "06665191a0c54bd7b1154b19f4911294",
            "e9f702fdffdc4a798cfab117042dff4a",
            "07233c046e3544c6a5bea9417d2218c8",
            "326f65aa53e543b9ab1f089cc9b287ee",
            "81f7786050d241c08574561226d4a59a",
            "b09cf23a87dc4f4f8a21b4ca55fed7b9",
            "96138c428784425298c99aed147b95fe",
            "68dcd340f4f045cfb62982fbfc4b11c6",
            "bb6cfc5b9e8846db9f6e8f705770a6e3",
            "7e7027e360a14773945fbca7d90f3ff2"
          ]
        },
        "id": "VKYP2VNkR-Gz",
        "outputId": "9308c11e-f5ee-4045-aea6-b98446664604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebfa5c16f6414b2db6f7c31085050d27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f57c649e718d42a98ef54d26d33189f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ed0a40ab8846b1b2f622d1de16e5df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ca915f709454cc3afdc462afe3099f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51d5bfacb7814ca7bba4e9535d8f5a22"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels, max_len):\n",
        "  # \uc815\uc218 \uc778\ucf54\ub529 \uacfc\uc815. \uac01 \ud14d\uc2a4\ud2b8\ub97c \ud1a0\ud070\ud654\ud55c \ud6c4\uc5d0 Vocabulary\uc5d0 \ub9f5\ud551\ub418\ub294 \uc815\uc218 \uc2dc\ud000\uc2a4\ub85c \ubcc0\ud658\ud55c\ub2e4.\n",
        "  # ex) ['\uc548\ub155\ud558\uc138\uc694'] ==> ['\uc548', '\ub155', '\ud558\uc138\uc694'] ==> [231, 52, 45]\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "  # pad_sequences\ub294 \ud328\ub529\uc744 \uc704\ud55c \ubaa8\ub4c8. \uc8fc\uc5b4\uc9c4 \ucd5c\ub300 \uae38\uc774\ub97c \uc704\ud574\uc11c \ub4a4\uc5d0\uc11c 0\uc73c\ub85c \ucc44\uc6cc\uc900\ub2e4.\n",
        "  # ex) [231, 52, 45] ==> [231, 52, 45, 0, 0, 0]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels, max_len)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels, max_len)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels, max_len)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IZUKR_j4fXjy",
        "outputId": "3bfab9df-7acd-4c5d-e328-358e5ebe5b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nRS_S-h6fYwZ",
        "outputId": "b444ce71-2216-4805-fa66-4f5c019610ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc:', test_inputs[0])\n",
        "print('-' * 20)\n",
        "print('\uc6d0\ubcf8 \ubb38\uc7a5 \ubcf5\uc6d0 \uacb0\uacfc:', tokenizer.decode(test_inputs[0]))\n",
        "print('-' * 20)\n",
        "print('\uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c:', test_masks[0])\n",
        "print('-' * 20)\n",
        "print('\uc0d8\ud50c\uc758 \uae38\uc774:', len(test_inputs[0]))\n",
        "print('-' * 20)\n",
        "print('\ub808\uc774\ube14:', test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3iI6nn6fZJD",
        "outputId": "ab7e726e-b52c-4acf-a4c0-ec71a4cb83ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\uc815\uc218 \uc778\ucf54\ub529 \uacb0\uacfc: tensor([    2,  5569,   647,  2194,  2131,  2391,  2116,  1521,  2371,  4683,\n",
            "         1160,  2460,  2496,  2918,  2118,  3869,  2496,  2203,  1280,  2052,\n",
            "         2515, 10257,  9478,     3,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "--------------------\n",
            "\uc6d0\ubcf8 \ubb38\uc7a5 \ubcf5\uc6d0 \uacb0\uacfc: [CLS] \uadf8\ub9cc\ud07c \uae38\uc608\ub974\ubaa8\uac00 \uc798\ud588\ub2e4\uace0 \ubcf4\uba74\ub418\uaca0\uc9c0 \uae30\ub300\ub418\ub124 \uc170\uc774\ud504 \uc624\ube0c \uc6cc\ud130 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "--------------------\n",
            "\uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "--------------------\n",
            "\uc0d8\ud50c\uc758 \uae38\uc774: 128\n",
            "--------------------\n",
            "\ub808\uc774\ube14: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "4HkyTKeaeTs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(train_labels))\n",
        "print('\uac80\uc99d \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(validation_labels))\n",
        "print('\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \ud06c\uae30:', len(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "ba3ccee9-b9bf-4616-a6ef-2560ff1d433a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30: 78977\n",
            "\uac80\uc99d \ub370\uc774\ud130\uc758 \ud06c\uae30: 8776\n",
            "\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \ud06c\uae30: 21939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU\uac00 \uc815\uc0c1 \uc14b\ud305\ub418\uc5c8\ub294\uc9c0 \ud655\uc778.  \n",
        "Colab\uc5d0\uc11c GPU\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc124\uc815\uc774 \ub418\uc5b4\uc788\uc5b4\uc57c\ub9cc \ud569\ub2c8\ub2e4.  \n",
        "\n",
        "* \ub7f0\ud0c0\uc784 > \ub7f0\ud0c0\uc784 \uc720\ud615 \ubcc0\uacbd > \ud558\ub4dc\uc6e8\uc5b4 \uac00\uc18d\uae30 > 'GPU' \uc120\ud0dd"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "69bd59c8-4874-4148-e071-c011ec9c5da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ubaa8\ub378 \ub85c\ub4dc\ud558\uae30"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935,
          "referenced_widgets": [
            "2edcebc4fa314c8f8ed77c886ef0bde1",
            "03ea7653c601428f926897d4e6f01bf4",
            "7b7491fe72b84d89818010fe689b71dc",
            "169e1691356047e09ee6bca1f522cd0e",
            "9f0a4fd821144e0a98c4ca3cf52b8bc1",
            "44ae71dd040b436ea929ba0bde0f8fda",
            "ae424858769c4d158964f485ce52698b",
            "01471cf9126c404fb4bd8ddbe071ff40",
            "f1c6f5e731e84ed196c946221ccffdc7",
            "0db7abf23ad14a25ab5412650f054a65",
            "bc9706b30ffd4dbca0f074e8b795dd5b"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "b7f2fe76-fc33-48fd-81de-feef7c1c40ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2edcebc4fa314c8f8ed77c886ef0bde1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \uc635\ud2f0\ub9c8\uc774\uc800 \uc120\ud0dd\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO_GNYxCSYfq",
        "outputId": "a7855eab-cc07-4202-d162-a5c85c97c50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \uba87 \ubc88\uc758 \uc5d0\ud3ec\ud06c(\uc804\uccb4 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ud559\uc2b5 \ud69f\uc218)\ub97c \ud560 \uac83\uc778\uc9c0 \uc120\ud0dd\n",
        "epochs = 4"
      ],
      "metadata": {
        "id": "sG4BGSrTx243"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    \"\"\"\n",
        "    \uba40\ud2f0\ub808\uc774\ube14 \ubd84\ub958 \ubb38\uc81c\uc758 \uc608\uce21\uac12\uacfc \uc2e4\uc81c \ub77c\ubca8\uc744 \uae30\ubc18\uc73c\ub85c \ub2e4\uc591\ud55c \ud3c9\uac00 \uc9c0\ud45c\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
        "    \uc774\ubbf8 \ud655\ub960\ub85c \ubcc0\ud658\ub41c \uc608\uce21\uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec, \uc784\uacc4\uac12\uc744 \uae30\uc900\uc73c\ub85c \ub808\uc774\ube14\uc744 \uacb0\uc815\ud558\uace0 \ud3c9\uac00 \uc9c0\ud45c\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
        "\n",
        "    Parameters:\n",
        "    predictions (numpy.ndarray): \ubaa8\ub378\uc5d0 \uc758\ud574 \uc608\uce21\ub41c \ud655\ub960\uac12. \uac01 \uc0d8\ud50c\uc5d0 \ub300\ud55c \ub808\uc774\ube14 \ud655\ub960\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.\n",
        "    labels (numpy.ndarray): \uc2e4\uc81c \ub77c\ubca8\uac12. \uac01 \uc0d8\ud50c\uc5d0 \ub300\ud55c \uc2e4\uc81c \ub808\uc774\ube14\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.\n",
        "    threshold (float): \ub808\uc774\ube14\uc744 \uacb0\uc815\ud558\uae30 \uc704\ud55c \uc784\uacc4\uac12. \uae30\ubcf8\uac12\uc740 0.5\uc785\ub2c8\ub2e4.\n",
        "\n",
        "    Returns:\n",
        "    dict: \ub2e4\uc591\ud55c \ud3c9\uac00 \uc9c0\ud45c(metrics)\uc5d0 \ub300\ud55c \uac12\ub4e4\uc744 \ub2f4\uc740 \uc0ac\uc804.\n",
        "    \"\"\"\n",
        "\n",
        "    # \uc784\uacc4\uac12\uc744 \ub118\ub294 \ud655\ub960 \uac12\uc744 \uac00\uc9c4 \uacbd\uc6b0 1\ub85c \uc608\uce21\ud588\ub2e4\uace0 \uac04\uc8fc\ud569\ub2c8\ub2e4.\n",
        "    y_pred = (predictions >= threshold).astype(int)\n",
        "\n",
        "    # \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba54\ud2b8\ub9ad\ub4e4\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n",
        "    accuracy = accuracy_score(labels, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=labels, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=labels, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=labels, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(labels, y_pred, average='micro')\n",
        "\n",
        "    # \uba54\ud2b8\ub9ad \uacb0\uacfc\uc5d0 \ub300\ud574\uc11c \ub9ac\ud134\ud569\ub2c8\ub2e4.\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ubaa8\ub378 \ud559\uc2b5"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_dataloader, optimizer, device):\n",
        "    \"\"\"\n",
        "    \ud558\ub098\uc758 \uc5d0\ud3ec\ud06c \ub3d9\uc548 \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\ub294 \ud568\uc218\uc785\ub2c8\ub2e4.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): \ud559\uc2b5\uc2dc\ud0ac \ubaa8\ub378 \uac1d\uccb4.\n",
        "    train_dataloader (torch.utils.data.DataLoader): \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc758 DataLoader.\n",
        "    optimizer (torch.optim.Optimizer): \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998\uc744 \uad6c\ud604\ud558\ub294 \uac1d\uccb4.\n",
        "    device (torch.device): \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud560 \uc7a5\uce58(CPU \ub610\ub294 CUDA).\n",
        "\n",
        "    Returns:\n",
        "    float: \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4\uac12.\n",
        "    \"\"\"\n",
        "\n",
        "    total_train_loss = 0  # \ud559\uc2b5 \uc190\uc2e4\uc744 \ub204\uc801\ud560 \ubcc0\uc218 \ucd08\uae30\ud654\n",
        "    model.train()  # \ubaa8\ub378\uc744 \ud559\uc2b5 \ubaa8\ub4dc\ub85c \uc124\uc815\n",
        "\n",
        "    # \ud559\uc2b5 \ub370\uc774\ud130\ub85c\ub354\ub97c \uc21c\ud68c\ud558\uba70 \ubc30\uce58 \ub2e8\uc704\ub85c \ud559\uc2b5\n",
        "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Training Batch\"):\n",
        "        batch = tuple(t.to(device) for t in batch)  # DataLoader\uc5d0\uc11c \ubc30\uce58\ub97c \ubc1b\uc544 \uac01 \ud150\uc11c\ub97c \uc9c0\uc815\ub41c \uc7a5\uce58\ub85c \uc774\ub3d9\n",
        "        b_input_ids, b_input_mask, b_labels = batch  # \ubc30\uce58\uc5d0\uc11c \uc785\ub825 ID, \ub9c8\uc2a4\ud06c, \ub77c\ubca8 \ucd94\ucd9c\n",
        "\n",
        "        # \ubaa8\ub378\uc5d0 \ubc30\uce58\ub97c \uc804\ub2ec\ud558\uc5ec \uc190\uc2e4\uac12 \uacc4\uc0b0\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        # \uc190\uc2e4\uac12 \ucd94\ucd9c\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()  # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n",
        "        loss.backward()  # \uc5ed\uc804\ud30c\ub97c \ud1b5\ud574 \uadf8\ub798\ub514\uc5b8\ud2b8 \uacc4\uc0b0\n",
        "        optimizer.step()  # \ub9e4\uac1c\ubcc0\uc218 \uc5c5\ub370\uc774\ud2b8\n",
        "\n",
        "        total_train_loss += loss.item()  # \ucd1d \uc190\uc2e4\uc5d0 \ub354\ud568\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)  # \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4 \uacc4\uc0b0\n",
        "\n",
        "    return avg_train_loss  # \ud3c9\uade0 \ud559\uc2b5 \uc190\uc2e4 \ubc18\ud658"
      ],
      "metadata": {
        "id": "y8rGFdrjfzed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, validation_dataloader, device):\n",
        "    \"\"\"\n",
        "    \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac80\uc99d \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ud3c9\uac00\ub97c \uc218\ud589\ud558\ub294 \ud568\uc218\uc785\ub2c8\ub2e4. \uc774 \ud568\uc218\ub294 \uba40\ud2f0\ub808\uc774\ube14 \ubd84\ub958 \ubb38\uc81c\uc5d0 \uc801\ud569\ud558\uac8c \uc124\uacc4\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n",
        "    \uac01 \ub808\uc774\ube14\uc5d0 \ub300\ud55c \uc608\uce21\uc744 \ub3c5\ub9bd\uc801\uc73c\ub85c \uc218\ud589\ud558\uace0, \uc5ec\ub7ec \ud3c9\uac00 \uc9c0\ud45c\ub97c \uacc4\uc0b0\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): \ud3c9\uac00\ud560 \ubaa8\ub378 \uac1d\uccb4. \uc774 \ubaa8\ub378\uc740 \uba40\ud2f0\ub808\uc774\ube14 \ubd84\ub958\ub97c \uc704\ud55c \ucd9c\ub825\uc744 \uc0dd\uc131\ud574\uc57c \ud569\ub2c8\ub2e4.\n",
        "    validation_dataloader (torch.utils.data.DataLoader): \uac80\uc99d \ub370\uc774\ud130\uc14b\uc758 DataLoader.\n",
        "    \uc774 DataLoader\ub294 \uc785\ub825 \ub370\uc774\ud130\uc640 \uc815\ub2f5 \ub808\uc774\ube14\uc744 \ubc30\uce58\ub85c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n",
        "    device (torch.device): \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ud560 \uc7a5\uce58(CPU \ub610\ub294 CUDA).\n",
        "\n",
        "    Returns:\n",
        "    float: \ud3c9\uade0 \uac80\uc99d \uc190\uc2e4\uac12. \uac80\uc99d \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc190\uc2e4\uc744 \ud3c9\uade0\ub0b8 \uac12\uc785\ub2c8\ub2e4.\n",
        "    dict: \ub2e4\uc591\ud55c \ud3c9\uac00 \uc9c0\ud45c(metrics)\uc5d0 \ub300\ud55c \uac12\ub4e4\uc744 \ub2f4\uc740 \uc0ac\uc804. \uc774 \uc0ac\uc804\uc740 \uc815\ud655\ub3c4(accuracy),\n",
        "    F1 \uc810\uc218(macro, micro, weighted) \ubc0f ROC-AUC \uc810\uc218\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # \ubaa8\ub378\uc744 \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    predictions, true_labels = [], []  # \ubaa8\ub378 \uc608\uce21 \ud655\ub960\uacfc \uc2e4\uc81c \ub77c\ubca8\uc744 \uc800\uc7a5\ud560 \ub9ac\uc2a4\ud2b8\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)  # \ubc30\uce58 \ub370\uc774\ud130\ub97c \ub514\ubc14\uc774\uc2a4\ub85c \uc774\ub3d9\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():  # \uadf8\ub798\ub514\uc5b8\ud2b8 \uacc4\uc0b0\uc744 \uc218\ud589\ud558\uc9c0 \uc54a\uc74c\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_eval_loss += loss.item()  # \ucd1d \uc190\uc2e4\uc5d0 \ub354\ud568\n",
        "\n",
        "        logits = outputs.logits.detach().cpu().numpy()  # \ubaa8\ub378 \uc608\uce21\uac12(\ub85c\uc9d3)\uc744 numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "        label_ids = b_labels.to('cpu').numpy()  # \uc2e4\uc81c \ub77c\ubca8\uac12\uc744 numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "\n",
        "        # \uc2dc\uadf8\ubaa8\uc774\ub4dc \ud568\uc218\ub97c \uc801\uc6a9\ud558\uc5ec \ub85c\uc9d3\uc744 \ud655\ub960\ub85c \ubcc0\ud658\n",
        "        # \uba40\ud2f0\ub808\uc774\ube14 \ubd84\ub958\uc5d0\uc11c\ub294 \uac01 \ub808\uc774\ube14\uc5d0 \ub300\ud55c \ub3c5\ub9bd\uc801\uc778 \uc608\uce21\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n",
        "        # \uc608\ub97c \ub4e4\uc5b4, logits \uac12\uc774 [-1.2, 2.3, -0.4, 1.0, -2.2, 0.5, -0.7, 1.2, 0.3]\ub85c \uc8fc\uc5b4\uc9c0\uace0,\n",
        "        # \uac01\uac01\uc758 \ub808\uc774\ube14\uc5d0 \ub300\ud574 \uc2dc\uadf8\ubaa8\uc774\ub4dc \ud568\uc218\ub97c \uc801\uc6a9\ud558\uba74, \ud655\ub960\uc740\n",
        "        # probs = [0.23, 0.91, 0.40, 0.73, 0.10, 0.62, 0.33, 0.77, 0.57]\uacfc \uac19\uc774 \uacc4\uc0b0\ub429\ub2c8\ub2e4.\n",
        "        # \uc2e4\uc81c \uc608\uce21 = [0 1 0 1 0 1 0 1 1]\n",
        "        sigmoid = torch.nn.Sigmoid()\n",
        "        probs = sigmoid(torch.Tensor(logits)).numpy()\n",
        "\n",
        "        predictions.extend(probs)\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    # multi_label_metrics \ud568\uc218\ub294 \uba40\ud2f0\ub808\uc774\ube14 \ud3c9\uac00 \uc9c0\ud45c \uacc4\uc0b0\uc744 \ud569\ub2c8\ub2e4.\n",
        "    # probs = [0.23, 0.91, 0.40, 0.73, 0.10, 0.62, 0.33, 0.77, 0.57] \uc774\ub77c\uace0 \uac00\uc815\ud558\uc600\uc744 \ub54c,\n",
        "    # \uc5ec\uae30\uc11c \uc784\uacc4\uac12(\uc608: 0.5)\uc744 \ub118\ub294 \ud655\ub960 \uac12\uc744 \uac00\uc9c4 \ub808\uc774\ube14\uc740 \ud574\ub2f9 \uc0d8\ud50c\uc5d0 \uc874\uc7ac\ud55c\ub2e4\uace0 \uc608\uce21\ud569\ub2c8\ub2e4.\n",
        "    # \uc704 \uc608\uc2dc\uc5d0\uc11c\ub294 \ub808\uc774\ube14 2, 4, 6, 8, 9\uac00 \uc784\uacc4\uac12\uc744 \ucd08\uacfc\ud558\ubbc0\ub85c, \ubaa8\ub378\uc758 \uc608\uce21 \ub808\uc774\ube14\uc740 [2, 4, 6, 8, 9]\uac00 \ub429\ub2c8\ub2e4.\n",
        "    eval_metrics = multi_label_metrics(np.array(predictions), np.array(true_labels))\n",
        "\n",
        "    avg_eval_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    return avg_eval_loss, eval_metrics"
      ],
      "metadata": {
        "id": "SsxmL2NVf4dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \ucd5c\uc18c \uac80\uc99d \uc190\uc2e4 \ucd08\uae30\ud654\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "# \uba54\uc778 \ud559\uc2b5 & \ud3c9\uac00 \ub8e8\ud504\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    # \ud559\uc2b5 \ub2e8\uacc4\n",
        "    train_epoch(model, train_dataloader, optimizer, device)\n",
        "\n",
        "    print(\"\\nRunning Validation...\")\n",
        "    # \uac80\uc99d \ub2e8\uacc4\n",
        "    avg_val_loss, eval_metrics = evaluate(model, validation_dataloader, device)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
        "    print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
        "    print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
        "    print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n",
        "\n",
        "    # \uac80\uc99d \uc190\uc2e4\uc774 \ud604\uc7ac\uae4c\uc9c0\uc758 \ucd5c\uc18c\uac12\ubcf4\ub2e4 \uc791\uc740 \uacbd\uc6b0 \uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\n",
        "    if avg_val_loss < min_val_loss:\n",
        "        print(f\"Validation loss decreased ({min_val_loss:.2f} --> {avg_val_loss:.2f}).  Saving model ...\")\n",
        "        # \ubca0\uc2a4\ud2b8 \ubaa8\ub378 \uc800\uc7a5\n",
        "        torch.save(model.state_dict(), 'model_checkpoint.pt')\n",
        "        # \ucd5c\uc18c \uac80\uc99d \uc190\uc2e4 \uc5c5\ub370\uc774\ud2b8\n",
        "        min_val_loss = avg_val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27VA0ZaBf8QM",
        "outputId": "8c018248-5e10-4f19-c29c-557ad837130b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 4 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1235/1235 [07:49<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.79\n",
            "  F1 Macro: 0.70\n",
            "  F1 Micro: 0.84\n",
            "  F1 Weighted: 0.83\n",
            "Validation loss decreased (inf --> 0.11).  Saving model ...\n",
            "======== Epoch 2 / 4 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1235/1235 [07:50<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.10\n",
            "  Accuracy: 0.80\n",
            "  F1 Macro: 0.71\n",
            "  F1 Micro: 0.85\n",
            "  F1 Weighted: 0.84\n",
            "Validation loss decreased (0.11 --> 0.10).  Saving model ...\n",
            "======== Epoch 3 / 4 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1235/1235 [07:50<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.10\n",
            "  Accuracy: 0.79\n",
            "  F1 Macro: 0.74\n",
            "  F1 Micro: 0.85\n",
            "  F1 Weighted: 0.85\n",
            "======== Epoch 4 / 4 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batch: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1235/1235 [07:50<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.80\n",
            "  F1 Macro: 0.75\n",
            "  F1 Micro: 0.85\n",
            "  F1 Weighted: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ubaa8\ub378 \uc800\uc7a5\uacfc \ub85c\ub4dc"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dEYcwOptN11n",
        "outputId": "389729c8-5727-4c0d-c574-4a4354f74817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -al"
      ],
      "metadata": {
        "id": "Vs2yEYOGN91l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7557f7d1-c91e-474b-c903-15ac4f9d5b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 432224\n",
            "drwxr-xr-x 1 root root      4096 Feb 14 12:21 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root      4096 Feb 14 11:47 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root      4096 Feb 12 14:21 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root 442580501 Feb 14 13:11 model_checkpoint.pt\n",
            "drwxr-xr-x 1 root root      4096 Feb 12 14:22 \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \ubca0\uc2a4\ud2b8 \ubaa8\ub378 \ub85c\ub4dc\n",
        "model.load_state_dict(torch.load(\"model_checkpoint.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "e27cbb1e-0d2c-4096-bf20-cfa2ddbaa602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ud3c9\uac00"
      ],
      "metadata": {
        "id": "8qSHpWCdOiPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_val_loss, eval_metrics = evaluate(model, test_dataloader, device)\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n",
        "print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n",
        "print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n",
        "print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "8cf4ad33-4ddb-4d27-ddb0-bf1fde636b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Loss: 0.10\n",
            "  Accuracy: 0.80\n",
            "  F1 Macro: 0.72\n",
            "  F1 Micro: 0.85\n",
            "  F1 Weighted: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \uc608\uce21"
      ],
      "metadata": {
        "id": "UC0ZwCb1OeBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "IJUifpTANkUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512,\n",
        "                return_all_scores=True, function_to_apply='sigmoid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KIEQnGPkM-",
        "outputId": "39b492fc-0e5b-4956-93b2-1b60662579ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('\ud2c0\ub2c8\ub4e4\uc740 \uc65c \uadf8\ub807\uac8c \ubbfc\ud3d0\ub97c \ub07c\uce58\ub0d0? \ud2b9\ud788 \ub098\uc774 \uba39\uc740 \ub0a8\uc790\ub4e4\uc774 \uc2ec\ud558\ub2e4')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmk18kVUQVwV",
        "outputId": "4ecece29-96d7-4dc2-c4ce-9c5c7e253c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.015342021360993385}, {'label': 'LABEL_1', 'score': 0.0297575443983078}, {'label': 'LABEL_2', 'score': 0.016898056492209435}, {'label': 'LABEL_3', 'score': 0.011106269434094429}, {'label': 'LABEL_4', 'score': 0.9612632393836975}, {'label': 'LABEL_5', 'score': 0.6780894994735718}, {'label': 'LABEL_6', 'score': 0.00563792372122407}, {'label': 'LABEL_7', 'score': 0.0076055387035012245}, {'label': 'LABEL_8', 'score': 0.020267454907298088}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'LABEL_0' : '\ucd9c\uc2e0\ucc28\ubcc4', 'LABEL_1' : '\uc678\ubaa8\ucc28\ubcc4', 'LABEL_2' : '\uc815\uce58\uc131\ud5a5\ucc28\ubcc4', \\\n",
        "              'LABEL_3': '\ud610\uc624\uc695\uc124', 'LABEL_4': '\uc5f0\ub839\ucc28\ubcc4', 'LABEL_5': '\uc131\ucc28\ubcc4', 'LABEL_6' : '\uc778\uc885\ucc28\ubcc4', \\\n",
        "              'LABEL_7': '\uc885\uad50\ucc28\ubcc4', 'LABEL_8': '\ud574\ub2f9\uc0ac\ud56d\uc5c6\uc74c'}"
      ],
      "metadata": {
        "id": "E-xQGKk4QZMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(text):\n",
        "  result = pipe(text)\n",
        "  return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]"
      ],
      "metadata": {
        "id": "hO2VS0j2Q3CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('\ud2c0\ub2c8\ub4e4\uc740 \uc65c \uadf8\ub807\uac8c \ubbfc\ud3d0\ub97c \ub07c\uce58\ub0d0? \ud2b9\ud788 \ub098\uc774 \uba39\uc740 \ub0a8\uc790\ub4e4\uc774 \uc2ec\ud558\ub2e4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onQ7KRNKRBKm",
        "outputId": "d45bf464-ead3-434e-81e2-9d0fdc6d49f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\uc5f0\ub839\ucc28\ubcc4', '\uc131\ucc28\ubcc4']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}